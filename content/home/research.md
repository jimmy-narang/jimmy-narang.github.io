---
widget: pages # As of v5.8-dev, 'pages' is renamed 'collection'
headless: true  # This file represents a page section.

# Put Your Section Options Here (title, background, etc.) ...
title: Research
subtitle: ''

# Position of this section on the page
weight: 20

content:
  # Filter content to display
  filters:
    # The folders to display content from
    folders:
      - post
    tag: ''
    category: ''
    publication_type: ''
    author: ''
    featured_only: false
    exclude_featured: false
    exclude_future: false
    exclude_past: false
  # Choose how many pages you would like to display (0 = all pages)
  count: 10
  # Choose how many pages you would like to offset by
  # Useful if you wish to show the first item in the Featured widget
  offset: 0
  # Field to sort by, such as Date or Title
  sort_by: 'Date'
  sort_ascending: false
design:
  # Choose a listing view
  view: compact
  # Choose how many columns the section has. Valid values: '1' or '2'.
  columns: '1'
---

## Sharing isn't Believing

Experimental evidence on coarse messaging and belief-formation in fake news.

People frequently share stories on social media with little additional context. I explore how this type of coarse messaging biases receivers' beliefs about the veracity of stories forwarded to them. Using a set of lab experiments in India with ~800 pairs of real-life friends, I collect detailed information on how individuals (sharers) decide which stories to forward, and how their friends (receivers) update their beliefs in response. I find that receivers over-interpret the act of forwarding a story as a sign of its veracity and discount other reasons for sharing. As a result, receivers' beliefs increase in forwarded stories irrespective of the sharers’ belief in them, with larger increases among false stories. By comparing receivers' updates on learning the sharer’s decisions to their updates on (i) learning the sharer’s beliefs directly, and (ii) learning computer-generated signals of fixed accuracy, I find several mechanisms that contribute to this aggregate bias: receivers overestimate how well their friends’ beliefs correlate with a story’s veracity; mispredict how beliefs translate into sharing decisions; and update in non-Bayesian ways such that their largest updates occur at lowest priors. I conclude with counterfactual exercises to identify the relative value of targeting each mechanism.
 
[Draft Here](https://www.dropbox.com/s/0si60kn7fjj16ky/draft.pdf?dl=0)  
_Updated frequently. Please check back for new versions._

<br/>

## Evaluating _Satyameva Jayate_: Kerala's high school program for digital literacy and reducing misinformation (In Progress) 
(with Mir Mohammed Ali).

In partnership with the government of Kerala (India), this randomized study will evaluate the effectiveness of a digital literacy program to reduce the spread of misinformation among high school students. The program, titled _Satyameva Jayate_ , is mandatory for the nearly three million students enrolled in government schools.  We plan to introduce new curriculum and treatments in addition to evaluating the program’s current version. 

<br/>

## Priors vs. Desires: what happens when biases interact (In Progress)

Lab studies with similar designs often find inconsistent results about the existence of motivated updating or confirmation bias. We hypothesize that these inconsistencies arise because studies conflate agreement with one’s priors (confirmation bias) with agreement with one’s desires (motivated updating or desirability bias); or ignore how these biases interact. Using data from studies in Psychology and Economics, and new data (collected for the job-maket paper), we examine how people update on good, bad and neutral news, across a range of priors and signal strengths. We find that confirmation bias is first-order, and mediates the extent to which desirability bias occurs. Participants' beliefs show almost no movement upon receiving news consistent with their priors, irrespective of favorability to their ego or politics. However, participants update considerably on disconfirming (surprising) news, with greater updates on good news and smaller updates on bad news.
