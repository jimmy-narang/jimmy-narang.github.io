---
widget: pages # As of v5.8-dev, 'pages' is renamed 'collection'
headless: true  # This file represents a page section.

# Put Your Section Options Here (title, background, etc.) ...
title: Research
subtitle: ''

# Position of this section on the page
weight: 20

content:
  # Filter content to display
  filters:
    # The folders to display content from
    folders:
      - post
    tag: ''
    category: ''
    publication_type: ''
    author: ''
    featured_only: false
    exclude_featured: false
    exclude_future: false
    exclude_past: false
  # Choose how many pages you would like to display (0 = all pages)
  count: 10
  # Choose how many pages you would like to offset by
  # Useful if you wish to show the first item in the Featured widget
  offset: 0
  # Field to sort by, such as Date or Title
  sort_by: 'Date'
  sort_ascending: false
design:
  # Choose a listing view
  view: compact
  # Choose how many columns the section has. Valid values: '1' or '2'.
  columns: '1'
---

## Sharing isn't Believing: 

Experimental evidence on coarse messaging and belief-formation in fake news.

People frequently share stories on social media with little additional context. I explore how this type of coarse messaging biases receivers' beliefs about the veracity of stories forwarded to them. Using a set of lab experiments in India with ~800 pairs of real-life friends, I collect detailed information on how individuals (sharers) decide which stories to share, and how their friends (receivers) update their beliefs in response. I compare receivers' updates on forwarded stories to their updates on learning the sharer's beliefs directly, and find that receivers significantly overestimate the extent to which sharing decisions reflect sharer's beliefs, and the extent to which sharer's beliefs predict story veracity. Furthermore, receivers exhibit a form of selection neglect - they update identically on shared stories that their friends found credible, and those that their friends didn't find as credible but deemed worthy of sharing anyway (these stories are more likely to be false). Finally, I find that the largest increases in receivers' beliefs occur at the lowest priors, a form of non-bayesian updating that privileges increased belief in false stories. I conclude with implications for aggregate learning, and with counterfactual exercises to identify the relative value of targeting each of these mechanisms.
<br><br> 
[Draft Here](https://www.dropbox.com/s/0si60kn7fjj16ky/draft.pdf?dl=0) 

_Updated frequently. Please check back for new versions._


## Evaluating _Satyameva Jayate_: Kerala's high school program for digital literacy and reducing misinformation (In Progress) 
(with Mir Mohammed Ali).

In partnership with the government of Kerala (India), this randomized study will evaluate the effectiveness of a digital literacy program to reduce the spread of misinformation among high school students. The program, titled _Satyameva Jayate_ , is mandatory for the nearly three million students enrolled in government schools.  We plan to introduce new curriculum and treatments, in addition to evaluating the program’s current version. 

## Priors vs. Desires: what happens when biases conflict (In Progress)

Lab studies with similar designs often find contradictory results about the existence of motivated updating or confirmation bias. This paper attempts to understand why. We hypothesize that these inconsistencies arise because studies either conflate agreement with one’s priors (confirmation bias) with agreement with one’s desires (motivated updating or desirability bias), or ignore how these biases interact. By combining data from studies in psychology, lab experiments in Economics, and new rounds of data collected for my job-maket paper, I examine the interaction between these biases across different types of information (good, bad and neutral news). We find that confirmation bias is first-order, and mediates the extent to which desirability bias occurs. That is, participants' beliefs show almost no movement upon receiving a signal consistent with their priors, irrespective of the signals’ favorability to their ego or politics. However, a surprising (disconfirming) signal moves their beliefs considerably: if the signal is a pleasant surprise, participants over-update relative to the Bayesian benchmark; and if the signal is an unpleasant surprise, participants over-update, but to a lesser extent.

## 